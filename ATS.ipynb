{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project :Automated Resume Screening\n",
    "Created By Group_19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Collection and View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Skills: Market Analysis, Stakeholder Managemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IT Support Specialist</td>\n",
       "      <td>Skills: Troubleshooting, Active Directory, Tic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Skills: Node.js, SQL, JavaScript, HTML/CSS. Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Skills: HTML/CSS, JavaScript, React, Node.js. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>Skills: Network Security, Routing and Switchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Skills: JavaScript, SQL, React, Node.js. Exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Skills: AWS, CI/CD, Jenkins, Docker. Experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>System Administrator</td>\n",
       "      <td>Skills: Linux, Networking, Scripting, Windows....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Product Manager</td>\n",
       "      <td>Skills: Agile, Product Roadmap, Market Analysi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Back End Developer</td>\n",
       "      <td>Skills: API Development, Database Management, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Category                                             Resume\n",
       "0        Product Manager  Skills: Market Analysis, Stakeholder Managemen...\n",
       "1  IT Support Specialist  Skills: Troubleshooting, Active Directory, Tic...\n",
       "2   Full Stack Developer  Skills: Node.js, SQL, JavaScript, HTML/CSS. Ex...\n",
       "3   Full Stack Developer  Skills: HTML/CSS, JavaScript, React, Node.js. ...\n",
       "4       Network Engineer  Skills: Network Security, Routing and Switchin...\n",
       "5   Full Stack Developer  Skills: JavaScript, SQL, React, Node.js. Exper...\n",
       "6        DevOps Engineer  Skills: AWS, CI/CD, Jenkins, Docker. Experienc...\n",
       "7   System Administrator  Skills: Linux, Networking, Scripting, Windows....\n",
       "8        Product Manager  Skills: Agile, Product Roadmap, Market Analysi...\n",
       "9     Back End Developer  Skills: API Development, Database Management, ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Final_Resumes.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  500 non-null    object\n",
      " 1   Resume    500 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# To check null values on dataset is  present or not\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Category                                             Resume\n",
      "0        Product Manager  Skills: Market Analysis, Stakeholder Managemen...\n",
      "1  IT Support Specialist  Skills: Troubleshooting, Active Directory, Tic...\n",
      "2   Full Stack Developer  Skills: Node.js, SQL, JavaScript, HTML/CSS. Ex...\n",
      "3   Full Stack Developer  Skills: HTML/CSS, JavaScript, React, Node.js. ...\n",
      "4       Network Engineer  Skills: Network Security, Routing and Switchin...\n",
      "5   Full Stack Developer  Skills: JavaScript, SQL, React, Node.js. Exper...\n",
      "6        DevOps Engineer  Skills: AWS, CI/CD, Jenkins, Docker. Experienc...\n",
      "7   System Administrator  Skills: Linux, Networking, Scripting, Windows....\n",
      "8        Product Manager  Skills: Agile, Product Roadmap, Market Analysi...\n",
      "9     Back End Developer  Skills: API Development, Database Management, ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (assumed to be a CSV)\n",
    "data = pd.read_csv('Final_Resumes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category    0\n",
      "Resume      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Optionally, drop rows with missing data\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Resume_cleaned Job_Description_cleaned\n",
      "0  skill market analysis stakeholder management p...         product manager\n",
      "1  skill troubleshoot active directory ticketing ...      support specialist\n",
      "2  skill nodejs sql javascript htmlcss experience...         stack developer\n",
      "3  skill htmlcss javascript react nodejs experien...         stack developer\n",
      "4  skill network security routing switch tcpip ci...        network engineer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load the English language model in SpaCy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_text(text):\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text and remove stop words\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and len(token) > 2]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply text cleaning to both the 'Resume' and 'Job Description' columns\n",
    "data['Resume_cleaned'] = data['Resume'].apply(clean_text)\n",
    "data['Job_Description_cleaned'] = data['Category'].apply(clean_text)\n",
    "\n",
    "# Display cleaned data\n",
    "print(data[['Resume_cleaned', 'Job_Description_cleaned']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    skill market analysis stakeholder management p...\n",
      "1    skill troubleshoot active directory ticketing ...\n",
      "2    skill nodejs sql javascript htmlcss experience...\n",
      "3    skill htmlcss javascript react nodejs experien...\n",
      "4    skill network security routing switch tcpip ci...\n",
      "5    skill javascript sql react nodejs experience w...\n",
      "6    skill aws cicd jenkins docker experience work ...\n",
      "7    skill linux network script window experience w...\n",
      "8    skill agile product roadmap market analysis st...\n",
      "9    skill api development database management pyth...\n",
      "Name: text_combined, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Combine cleaned 'Resume' and 'Job Description' into a single text field\n",
    "data['text_combined'] = data['Resume_cleaned'] + ' ' + data['Job_Description_cleaned']\n",
    "\n",
    "# Display the combined text\n",
    "print(data['text_combined'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Convert Text into Numerical Features (Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 236)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limit to the top 5000 features\n",
    "\n",
    "# Fit and transform the combined text data\n",
    "X = tfidf_vectorizer.fit_transform(data['text_combined'])\n",
    "\n",
    "# Display the shape of the resulting feature matrix\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Target Variable Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 11 10 10 12 10  7 18 13  1  7 11 10 10  9 16 18  4 11  5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convert job categories to numerical labels\n",
    "y = label_encoder.fit_transform(data['Category'])\n",
    "\n",
    "# Display the encoded labels\n",
    "print(y[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 236) (150, 236) (350,) (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Display the shape of the split data\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the vectorizer and label encoder for later use\n",
    "import joblib\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Selection and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1: Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned resume data\n",
    "df = pd.read_csv(\"cleaned_resumes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(classification_report(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Support Vector Classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize K-Nearest Neighbors model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Model Evaluation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: SVM\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: Naive Bayes\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "--------------------------------------------------\n",
      "Model: KNN\n",
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         7\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         3\n",
      "           7       1.00      1.00      1.00        13\n",
      "           8       1.00      1.00      1.00         7\n",
      "           9       1.00      1.00      1.00         7\n",
      "          10       1.00      1.00      1.00         8\n",
      "          11       1.00      1.00      1.00         9\n",
      "          12       1.00      1.00      1.00         4\n",
      "          13       1.00      1.00      1.00        12\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       1.00      1.00      1.00         5\n",
      "          16       1.00      1.00      1.00         6\n",
      "          17       1.00      1.00      1.00         8\n",
      "          18       1.00      1.00      1.00         8\n",
      "          19       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00       150\n",
      "   macro avg       1.00      1.00      1.00       150\n",
      "weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Summary of model performance\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"SVM\": svm,\n",
    "    \"Random Forest\": rf,\n",
    "    \"Naive Bayes\": nb,\n",
    "    \"KNN\": knn\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resume_screening_model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model (Random Forest in this case)\n",
    "joblib.dump(rf, 'resume_screening_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Enhancing with Resume Accuracy & Skill Suggestions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Code for Resume Accuracy (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_resume_accuracy(resume_text, job_description, vectorizer):\n",
    "    # Vectorize the resume and job description\n",
    "    resume_vector = vectorizer.transform([resume_text])\n",
    "    job_description_vector = vectorizer.transform([job_description])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_score = cosine_similarity(resume_vector, job_description_vector)[0][0]\n",
    "\n",
    "    # Return the accuracy score as a percentage\n",
    "    return round(similarity_score * 100, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Skill Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Skills: ['Machine Learning', 'Deep Learning', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "# Example list of skills relevant to the job description\n",
    "job_skills = ['Python', 'Machine Learning', 'Data Analysis', 'SQL', 'Deep Learning', 'NLP']\n",
    "\n",
    "# Extract skills from resume (this can be improved with NER or pattern matching)\n",
    "def extract_skills_from_resume(resume_text):\n",
    "    # List of example skills from the resume\n",
    "    resume_skills = ['Python', 'SQL', 'Data Analysis']  # This should be extracted from resume_text in a real system\n",
    "    return resume_skills\n",
    "\n",
    "# Function to suggest missing skills\n",
    "def suggest_skills(resume_skills, job_skills):\n",
    "    # Identify missing skills\n",
    "    missing_skills = [skill for skill in job_skills if skill not in resume_skills]\n",
    "    return missing_skills\n",
    "\n",
    "# Example usage\n",
    "resume_text = \"Experienced in Python and SQL for data analysis.\"\n",
    "resume_skills = extract_skills_from_resume(resume_text)\n",
    "missing_skills = suggest_skills(resume_skills, job_skills)\n",
    "\n",
    "print(\"Missing Skills:\", missing_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define skills for each job category\n",
    "skills_dict = {\n",
    "    'Data Scientist': ['Python', 'R', 'Machine Learning', 'Data Analysis'],\n",
    "    'Software Engineer': ['Java', 'C++', 'Algorithms', 'Data Structures'],\n",
    "    # Add more job categories and skills\n",
    "}\n",
    "\n",
    "# Suggest missing skills\n",
    "def suggest_missing_skills(job_category, resume_text):\n",
    "    required_skills = skills_dict.get(job_category, [])\n",
    "    suggested_skills = [skill for skill in required_skills if skill not in resume_text]\n",
    "    return suggested_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict job category, accuracy, and suggest skills\n",
    "def screen_resume(resume_text, job_desc):\n",
    "    # Combine resume text with job description\n",
    "    text_combined = resume_text + ' ' + job_desc\n",
    "    \n",
    "    # Convert text to numerical form using saved TF-IDF vectorizer\n",
    "    text_vector = tfidf_vectorizer.transform([text_combined])\n",
    "    \n",
    "    # Predict job category using the loaded model\n",
    "    predicted_job_category = rf_model.predict(text_vector)[0]\n",
    "    \n",
    "    # Get resume accuracy\n",
    "    accuracy_score = get_resume_accuracy()\n",
    "    \n",
    "    # Suggest missing skills\n",
    "    suggested_skills = suggest_missing_skills(predicted_job_category, resume_text)\n",
    "    \n",
    "    return predicted_job_category, accuracy_score, suggested_skills\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
